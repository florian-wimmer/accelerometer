{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from scipy.signal import iirfilter, filtfilt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import dill\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\"\"\"\n",
    "Date: 2024-06-20 15:47:56,,,,,,\n",
    "Calibration: XL_ODR: 6667Hz, XL_FS: 16g, GY_ODR: 6667Hz, GY_FS: 2000dps,,,\n",
    "Time(s),Acceleration X (g),Acceleration Y (g),Acceleration Z (g),Angular Momentum X (dps),Angular Momentum Y (dps),Angular Momentum Z (dps)\n",
    "0.000083,0.693359,-0.720215,0.14209,-3.540039,0.366211,-3.051758\n",
    "0.00098,0.70752,-0.755371,0.086914,1.953125,0.732422,-1.159668\n",
    "\"\"\"\n",
    "\n",
    "# Check if GPU is available and use it if possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Helper module to trim convolution output to the original sequence length.\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, : -self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "# A single Temporal Block (residual block) including two dilated convolution layers.\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernel_size, stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1, self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "# The TCN model composed of multiple Temporal Blocks.\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        \"\"\"\n",
    "        num_inputs: Number of features per time step.\n",
    "        num_channels: List of output channels for each Temporal Block.\n",
    "        \"\"\"\n",
    "        super(TCN, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2**i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i - 1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size, padding=(kernel_size - 1) * dilation_size, dropout=dropout)]\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.fc = nn.Linear(num_channels[-1], 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, features)\n",
    "        x = x.transpose(1, 2)  # (batch, features, seq_len)\n",
    "        y = self.network(x)\n",
    "        y = y[:, :, -1]  # take the output of the final time step\n",
    "        y = self.fc(y)\n",
    "        y = self.sigmoid(y)\n",
    "        return y\n",
    "    \n",
    "class TimeSeriesDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels, seq_len, step):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.seq_len = seq_len\n",
    "        self.step = step\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - (self.seq_len - 1) * self.step\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indices = [idx + i * self.step for i in range(self.seq_len)]\n",
    "        x_seq = self.data[indices]\n",
    "        y_val = self.labels[indices[-1]]\n",
    "        return x_seq, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data = pd.read_csv(r\"../measurement/processed_data/kanguru_train.csv\", header=2)\n",
    "\n",
    "window_size = 10\n",
    "averaged_rows = []\n",
    "\n",
    "for i in range(0, len(train_data), window_size):\n",
    "    chunk = train_data.iloc[i : i + window_size]\n",
    "    chunk_mean = chunk.mean(numeric_only=True)\n",
    "    # Use mean time for the new row\n",
    "    chunk_mean[\"Time(s)\"] = chunk[\"Time(s)\"].mean()\n",
    "    averaged_rows.append(chunk_mean)\n",
    "\n",
    "train_data = pd.DataFrame(averaged_rows, columns=train_data.columns)\n",
    "\n",
    "X_train = train_data[[\"Time(s)\", \"Acceleration X (g)\", \"Acceleration Y (g)\", \"Acceleration Z (g)\", \"Angular Momentum X (dps)\", \"Angular Momentum Y (dps)\", \"Angular Momentum Z (dps)\"]]\n",
    "y_train = train_data[\"Stand detected\"]\n",
    "\n",
    "# Compute sampling frequency and filter parameters\n",
    "sampling_frequency = 1 / (train_data[\"Time(s)\"].diff().mean())\n",
    "cutoff_frequency = 100\n",
    "b, a = iirfilter(4, Wn=cutoff_frequency, fs=sampling_frequency, btype=\"low\", ftype=\"butter\")\n",
    "\n",
    "# Apply filter, standardize and weight features\n",
    "X_train_filtered = X_train.copy()\n",
    "X_train_filtered.iloc[:, 1:] = filtfilt(b, a, X_train.iloc[:, 1:], axis=0)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_filtered.iloc[:, 1:])\n",
    "feature_weights = np.array([1, 1, 1, 1, 1, 1])\n",
    "X_train_weighted = (X_train_scaled * feature_weights).astype(np.float32)\n",
    "\n",
    "# Convert to tensor\n",
    "X_train_tensor = torch.tensor(X_train_weighted)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "\n",
    "# Reintroduce the custom TimeSeriesDataset with sequence length and step\n",
    "sequence_length = 10\n",
    "step = 10\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataset(X_train_tensor, y_train_tensor, sequence_length, step)\n",
    "train_loader =  torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define TCN model instance\n",
    "num_features = X_train_tensor.shape[1]\n",
    "model = TCN(num_inputs=num_features, num_channels=[32, 32], kernel_size=2, dropout=0.2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 25\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "        for batch_X, batch_y in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # TCN expects input shape (batch, seq_len, features)\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs.squeeze(), batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tepoch.set_postfix(loss=loss.item())\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "torch.save(model.state_dict(), \"model/tcn_kang_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TCN(num_inputs=X_train_tensor.shape[1], num_channels=[32, 32], kernel_size=2, dropout=0.2).to(device)\n",
    "model.load_state_dict(torch.load('model/tcn_kang_model.pth'))\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv(r\"../measurement/processed_data/kanguru_test.csv\", header=2)\n",
    "\n",
    "averaged_rows = []\n",
    "\n",
    "for i in range(0, len(test_data), window_size):\n",
    "    chunk = test_data.iloc[i : i + window_size]\n",
    "    chunk_mean = chunk.mean(numeric_only=True)\n",
    "    # Use mean time for the new row\n",
    "    chunk_mean[\"Time(s)\"] = chunk[\"Time(s)\"].mean()\n",
    "    averaged_rows.append(chunk_mean)\n",
    "\n",
    "test_data = pd.DataFrame(averaged_rows, columns=test_data.columns)\n",
    "\n",
    "X_test = test_data[[\"Time(s)\", \"Acceleration X (g)\", \"Acceleration Y (g)\", \"Acceleration Z (g)\", \"Angular Momentum X (dps)\", \"Angular Momentum Y (dps)\", \"Angular Momentum Z (dps)\"]]\n",
    "\n",
    "# Apply IIR filter to test data (excluding time series)\n",
    "X_test_filtered = X_test.copy()\n",
    "X_test_filtered.iloc[:, 1:] = filtfilt(b, a, X_test.iloc[:, 1:], axis=0)\n",
    "\n",
    "# Standardize the test data\n",
    "X_test_scaled = scaler.transform(X_test_filtered.iloc[:, 1:])\n",
    "\n",
    "# Convert test data to PyTorch tensor\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "# Prepare test dataset with sequence windows and change to batch prediction\n",
    "test_dataset = TimeSeriesDataset(X_test_tensor, torch.zeros(len(X_test_tensor)), sequence_length, 10)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "all_preds = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_X, _ in test_loader:\n",
    "        batch_X = batch_X.to(device)  # shape: (batch, seq_len, features)\n",
    "        batch_preds = model(batch_X).squeeze() > 0.5\n",
    "        all_preds.extend(batch_preds.tolist())\n",
    "\n",
    "# Align predictions with the original test indices.\n",
    "\n",
    "pred_array = np.full(len(X_test_tensor), np.nan)\n",
    "for i, pred in enumerate(all_preds):\n",
    "    index = i + (sequence_length - 1) * step\n",
    "    if index < len(pred_array):\n",
    "        pred_array[index] = pred\n",
    "\n",
    "test_data[\"predicted_heel_button\"] = pred_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Angular Momentum Z axis (filtered and scaled)\n",
    "fig = go.Figure()\n",
    "# [:, 5]\n",
    "fig.add_trace(go.Scatter(x=test_data[\"Time(s)\"], y=X_test_scaled[:, 0], mode=\"lines\", name=\"AC X (Filtered & Scaled)\"))\n",
    "fig.add_trace(go.Scatter(x=test_data[\"Time(s)\"], y=X_test_scaled[:, 1], mode=\"lines\", name=\"AC Y (Filtered & Scaled)\"))\n",
    "fig.add_trace(go.Scatter(x=test_data[\"Time(s)\"], y=X_test_scaled[:, 5], mode=\"lines\", name=\"AM Z (Filtered & Scaled)\"))\n",
    "fig.add_trace(go.Scatter(x=test_data[\"Time(s)\"], y=test_data[\"Stand detected\"], mode=\"lines\", name=\"Heel Button\"))\n",
    "#fig.add_trace(go.Scatter(x=test_data[\"Time(s)\"], y=test_data[\"Stand detected\"], mode=\"lines\", name=\"Analytical\"))\n",
    "fig.add_trace(go.Scatter(x=test_data[\"Time(s)\"], y=test_data[\"predicted_heel_button\"], mode=\"lines\", name=\"Predicted Heel Button\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"Time(s)\"] = test_data[\"Time(s)\"] - test_data.iloc[0][\"Time(s)\"]\n",
    "test_data.to_csv(\"../measurement/processed_data/comparison_kang/tcn_test.csv\")\n",
    "\n",
    "test_data = test_data[test_data[\"Time(s)\"] > 0.3]\n",
    "test_data[\"Time(s)\"] = test_data[\"Time(s)\"] - test_data.iloc[0][\"Time(s)\"]\n",
    "\n",
    "equal_values = (test_data[\"predicted_heel_button\"] == test_data[\"Stand detected\"]).sum()\n",
    "print(f\"{equal_values} out of {test_data.shape[0]} entries are equal, which is {equal_values / test_data.shape[0] * 100:.2f}%\")\n",
    "\n",
    "def count_artifacts(pred_signal, time_vector, threshold_0=0.05, threshold_1=0.15):\n",
    "    \"\"\"\n",
    "    Counts artifacts in a binary step signal based on duration thresholds.\n",
    "    \n",
    "    Args:\n",
    "        pred_signal (np.array): Array of predicted values (0 or 1).\n",
    "        time_vector (np.array): Array of corresponding time values.\n",
    "        threshold_0 (float): Minimum duration in seconds for a valid 0 segment.\n",
    "        threshold_1 (float): Minimum duration in seconds for a valid 1 segment.\n",
    "        \n",
    "    Returns:\n",
    "        Tuple (count_zero, count_one): Number of artifact segments for 0 and 1.\n",
    "    \"\"\"\n",
    "    n = len(pred_signal)\n",
    "    count_zero = 0\n",
    "    count_one = 0\n",
    "    start_idx = 0\n",
    "\n",
    "    while start_idx < n:\n",
    "        current = pred_signal[start_idx]\n",
    "        end_idx = start_idx + 1\n",
    "        while end_idx < n and pred_signal[end_idx] == current:\n",
    "            end_idx += 1\n",
    "\n",
    "        # Compute segment duration\n",
    "        duration = time_vector[end_idx - 1] - time_vector[start_idx]\n",
    "\n",
    "        if current == 0 and duration < threshold_0:\n",
    "            count_zero += 1\n",
    "        elif current == 1 and duration < threshold_1:\n",
    "            count_one += 1\n",
    "\n",
    "        start_idx = end_idx\n",
    "\n",
    "    return count_zero, count_one\n",
    "\n",
    "count_zero, count_one = count_artifacts(test_data[\"predicted_heel_button\"].values, test_data[\"Time(s)\"].values)\n",
    "print(f\"Number of short 0 segments (artifacts): {count_zero}\")\n",
    "print(f\"Number of short 1 segments (artifacts): {count_one}\")\n",
    "\n",
    "print(f\" {equal_values / test_data.shape[0] * 100:.2f}; {count_zero}; {count_one};\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
